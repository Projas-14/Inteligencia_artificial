{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwZZb6T2b3l/0msEx+OFKs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Projas-14/Inteligencia_artificial/blob/master/Clasificaci%C3%B3n%20de%20Opiniones%20de%20Pel%C3%ADculas%20con%20Redes%20Neuronales%20Recurrentes%20(RNN).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clasificación de Opiniones de Películas con Redes Neuronales Recurrentes (RNN)\n",
        "\n",
        "**Descripción del Proyecto:**\n",
        "\n",
        "En este proyecto, vamos a construir un modelo de aprendizaje profundo utilizando redes neuronales recurrentes (RNN) para clasificar opiniones de películas como positivas o negativas utilizando el conjunto de datos IMDB. Las RNN son especialmente adecuadas para procesar secuencias de datos, como texto, y son ampliamente utilizadas en tareas de procesamiento del lenguaje natural (NLP)."
      ],
      "metadata": {
        "id": "RZNB_DODgCnA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pasos a seguir:\n",
        "\n",
        "Carga de Datos:\n",
        "\n",
        "Cargar el conjunto de datos IMDB, que ya está disponible en keras.datasets."
      ],
      "metadata": {
        "id": "p55puTmtgKXN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1d2TlQ5f5rD",
        "outputId": "d05b708d-a57b-42b2-c5e3-92994b60e212"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Importar las bibliotecas necesarias\n",
        "import numpy as np\n",
        "from keras.datasets import imdb\n",
        "\n",
        "# Cargar el conjunto de datos IMDB\n",
        "vocabulario = 10000  # Tamaño del vocabulario (las 10000 palabras más frecuentes)\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocabulario)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocesamiento de Datos:\n",
        "\n",
        "Convertir las opiniones de las películas en secuencias de números utilizando tokenización y padding.\n",
        "Dividir los datos en conjuntos de entrenamiento y prueba."
      ],
      "metadata": {
        "id": "4qj3MxuCgoAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocesamiento de datos: Padding de secuencias\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "max_longitud = 200  # Máxima longitud de la secuencia (en palabras)\n",
        "X_train = pad_sequences(X_train, maxlen=max_longitud)\n",
        "X_test = pad_sequences(X_test, maxlen=max_longitud)\n"
      ],
      "metadata": {
        "id": "-biSYjKxhI5d"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construcción del Modelo:\n",
        "\n",
        "Construir una red neuronal recurrente (RNN) utilizando capas de embeddings y capas LSTM (Long Short-Term Memory).\n",
        "Compilar el modelo con una función de pérdida adecuada y un optimizador."
      ],
      "metadata": {
        "id": "9WQVQdCZhOs7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Construir el modelo RNN\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "embedding_dim = 128\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocabulario, embedding_dim, input_length=max_longitud))\n",
        "model.add(LSTM(64, return_sequences=True))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "8mt_syj2hM7h"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamiento del Modelo:\n",
        "\n",
        "Entrenar el modelo utilizando el conjunto de entrenamiento.\n",
        "\n",
        "Monitorear el rendimiento del modelo en el conjunto de validación y ajustar los hiperparámetros si es necesario."
      ],
      "metadata": {
        "id": "-c6D5HR0hV3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar el modelo\n",
        "history = model.fit(X_train, y_train, epochs=5, batch_size=128, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfGN_-NWhaUH",
        "outputId": "a3407ba3-a7aa-4a4c-ce5b-cf64929b67d5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "157/157 [==============================] - 110s 676ms/step - loss: 0.4296 - accuracy: 0.7948 - val_loss: 0.3183 - val_accuracy: 0.8636\n",
            "Epoch 2/5\n",
            "157/157 [==============================] - 112s 713ms/step - loss: 0.2217 - accuracy: 0.9157 - val_loss: 0.3142 - val_accuracy: 0.8712\n",
            "Epoch 3/5\n",
            "157/157 [==============================] - 106s 673ms/step - loss: 0.1475 - accuracy: 0.9491 - val_loss: 0.3653 - val_accuracy: 0.8482\n",
            "Epoch 4/5\n",
            "157/157 [==============================] - 107s 681ms/step - loss: 0.1087 - accuracy: 0.9616 - val_loss: 0.3673 - val_accuracy: 0.8642\n",
            "Epoch 5/5\n",
            "157/157 [==============================] - 104s 665ms/step - loss: 0.0745 - accuracy: 0.9757 - val_loss: 0.4665 - val_accuracy: 0.8638\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluación del Modelo:\n",
        "\n",
        "Evaluar el rendimiento del modelo utilizando el conjunto de prueba.\n",
        "Visualizar las métricas de rendimiento, como precisión y pérdida, a lo largo del tiempo."
      ],
      "metadata": {
        "id": "0Axn3TH8jjXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluar el modelo\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Pérdida en el conjunto de prueba:\", loss)\n",
        "print(\"Precisión en el conjunto de prueba:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBCRHxXhjm07",
        "outputId": "96b41597-99f1-46f7-a9f5-ecfb6ef6f416"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 56s 72ms/step - loss: 0.5002 - accuracy: 0.8506\n",
            "Pérdida en el conjunto de prueba: 0.5002129077911377\n",
            "Precisión en el conjunto de prueba: 0.8505600094795227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimización del Modelo:\n",
        "\n",
        "Experimentar con diferentes arquitecturas de redes neuronales, hiperparámetros y técnicas de regularización para mejorar el rendimiento del modelo.\n",
        "\n",
        "Para optimizar el modelo, podríamos experimentar con diferentes arquitecturas de redes neuronales, hiperparámetros y técnicas de regularización. Por ejemplo, podríamos probar diferentes valores de la tasa de aprendizaje del optimizador Adam o ajustar el tamaño de las capas LSTM."
      ],
      "metadata": {
        "id": "PXIGKKM9juPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experimentar con diferentes hiperparámetros y arquitecturas de redes neuronales\n",
        "# Por ejemplo, podemos probar una LSTM bidireccional o agregar capas Dropout para regularización\n",
        "from keras.layers import Bidirectional, Dropout\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocabulario, embedding_dim, input_length=max_longitud))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=128, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XEbAppKj0rM",
        "outputId": "18fc63dc-a250-4b96-9c3b-67e559624d1f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "157/157 [==============================] - 214s 1s/step - loss: 0.4224 - accuracy: 0.7964 - val_loss: 0.3093 - val_accuracy: 0.8674\n",
            "Epoch 2/5\n",
            "157/157 [==============================] - 203s 1s/step - loss: 0.2213 - accuracy: 0.9182 - val_loss: 0.3517 - val_accuracy: 0.8710\n",
            "Epoch 3/5\n",
            "157/157 [==============================] - 200s 1s/step - loss: 0.1398 - accuracy: 0.9521 - val_loss: 0.4346 - val_accuracy: 0.8596\n",
            "Epoch 4/5\n",
            "157/157 [==============================] - 199s 1s/step - loss: 0.0981 - accuracy: 0.9675 - val_loss: 0.4178 - val_accuracy: 0.8600\n",
            "Epoch 5/5\n",
            "157/157 [==============================] - 200s 1s/step - loss: 0.1223 - accuracy: 0.9553 - val_loss: 0.4488 - val_accuracy: 0.8462\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fc6a8326200>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Despliegue del Modelo\n",
        "Guardar el modelo entrenado para su uso futuro y/o implementar una interfaz donde los usuarios puedan ingresar reseñas de películas y obtener la predicción del modelo.\n",
        "\n",
        "Para desplegar el modelo entrenado, podemos guardar el modelo en un archivo y luego cargarlo para hacer predicciones sobre nuevas reseñas de películas."
      ],
      "metadata": {
        "id": "LrIBf6PKkCm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el modelo entrenado\n",
        "model.save('imdb_rnn_model.h5')\n",
        "\n",
        "# Cargar el modelo para hacer predicciones\n",
        "from keras.models import load_model\n",
        "\n",
        "loaded_model = load_model('imdb_rnn_model.h5')\n",
        "\n",
        "# Ejemplo de predicción sobre una nueva reseña de película\n",
        "new_review = \"This movie was amazing! I loved every moment of it.\"\n",
        "# Preprocesar la nueva reseña\n",
        "new_review_encoded = imdb.get_word_index()\n",
        "new_review_sequence = [new_review_encoded[word] if word in new_review_encoded and new_review_encoded[word] < vocabulario else 0 for word in new_review.split()]\n",
        "new_review_padded = pad_sequences([new_review_sequence], maxlen=max_longitud)\n",
        "# Realizar la predicción\n",
        "prediction = loaded_model.predict(new_review_padded)\n",
        "if prediction >= 0.5:\n",
        "    print(\"La reseña es positiva.\")\n",
        "else:\n",
        "    print(\"La reseña es negativa.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I32dtOhrkRta",
        "outputId": "58594295-22fa-4162-9502-cefcd4f1e2ae"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "La reseña es negativa.\n"
          ]
        }
      ]
    }
  ]
}